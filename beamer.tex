\documentclass{beamer}
%\documentclass[trans]{beamer}

% use the 'trans' to produce "transperencies"; really this means: something you
% would *print*. -- The \pause command does nothing when the option
% [trans] is used.

\usepackage{palatino}
\usepackage{mathpazo}

\usepackage{graphicx}
%\graphicspath{ {./} }

%%------------------------------------------------------------
%% some "theorem" commands

\newtheorem{cor}[theorem]{Corollary}
\newtheorem{prop}[theorem]{Proposition}

\theoremstyle{remark}
\newtheorem{rem}[theorem]{Remark}


%%------------------------------------------------------------

\mode<presentation>
{
  \usetheme{CambridgeUS}
% other options include
%  \usetheme{Rochester}
%  \usetheme{boxes}
% or ...

  \setbeamercovered{transparent}
}

\usepackage[english]{babel}

\usefonttheme{serif}
\useinnertheme{rectangles}

\title{Linear Algebraic Groups and Lie Algebras}
\subtitle[]{First Principles to Semisimple Classification}

\date{April 19th, 2024}

\author[] % (optional, use only with lots of authors)
{Eric Tao}
\institute{Tufts University}

%\subject{Talks}
% This is only inserted into the PDF information catalog. Can be left
% out. 

% Remove ("comment out") the following code if you do not want the
% table of contents to pop up at the beginning of each subsection:

\AtBeginSection[]
{
  \begin{frame}%<beamer>
    \frametitle{Outline}
    \tableofcontents[currentsection]
  \end{frame}
}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 

%\beamerdefaultoverlayspecification{<+->}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}


%% I've commented this out since the "pre-section" table of contents will anyhow appear...
%%
%  \begin{frame}
%    \frametitle{Overview}
%    \tableofcontents
%    % You might wish to add the option [pausesections]
%  \end{frame}

%\section{Beamer warmup}

%\begin{frame}
  %\frametitle{Beamer concepts}

%  \begin{itemize}
  %\item   A slide is the basic unit for a \emph{Beamer} slide-show.
   % \pause

  %\item I've organized this document with \emph{sections}; each section contains a few \emph{frames.}
  %  \pause

 % \item When the \textsc{LaTeX} file is \emph{compiled} (say, in \textsc{Overleaf}) the output
 %   is a PDF file that has (at least) a page corresponding to  each frame.
  %\end{itemize}

%\end{frame}

%\begin{frame}
  %\frametitle{Beamer concepts, p.2}
  
%  \begin{itemize}
  %\item In fact, if there are \texttt{\textbackslash pause} commands
    %with a frame, \textsc{LaTeX} will produce multiple pages for the
    %frame, with material following the \texttt{\textbackslash pause}
    %\emph{greyed out}.
   % \pause
 % \item Using an application for document display, you can use the
%    resulting PDF to accompany a presentation.

%  \end{itemize}
%\end{frame}

\section{Linear Algebraic Groups}
\begin{frame}
  \frametitle{Definition of a Linear Algebraic Group} 
  \begin{itemize}
  \item A \emph{linear algebraic group} $G$ is an affine variety equipped with a compatible group structure.
    \pause
  \item In particular, the group operations multiplication $\mu: G \times G \to G$ and inversion $i: G \to G$ act as morphism of varieties.   \pause
  \item Clearly, Zariski closed subgroups of the general linear group $GL_n$ are linear algebraic groups. A theorem can be proved that every algebraic group may be embedded as a closed subgroup of $GL_n$ for some $n$.
  \end{itemize} 
  % here, we should discuss the variety xy - 1, and embed that into GL_2 via [[x,0],[0,y]]
\end{frame}

\begin{frame}
\frametitle{Some Algebraic Terminology}
\begin{itemize}
\item For the following, let $G$ be a group.
\pause
\item For $g, h \in G$, define the commutator that sends $(g,h) \mapsto gh g^{-1}h^{-1}$. Define $[G, G]$ as the subgroup generated by all commutators of $G$ with $G$.
\pause
\item We call $G$ solvable if, for $G^{(0)} = G$, and $G^{(i)} = [ G^{(i-1)}, G^{(i-1)}]$, $G^{(i)}$ is trivial for some $i$.
\pause
\item Similarly, we call $G$ nilpotent if, for $G^0 = G$, and $G^i = [ G^{i-1}, G]$, $G^i$ is trivial for some $i$.
\pause
\item Evidently, if $G$ is nilpotent, certainly $G$ is solvable. % show this
\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Jordan Decomposition} 

  \begin{itemize}
  \item The ability to embed a linear algebraic group into matrix groups allows us to characterize elements by properties of the matrix representation, assuming this is independent of representation.
    \pause
  \item In particular, we can define a \emph{Jordan decomposition} for linear algebraic groups.

    \pause
    \item If $g \in G$, then there exists a $g_s, g_u \in G$ with the representation of $g_s$ semisimple, $g_u$ unipotent and $g = g_s g_u = g_u g_s$. Moreover, the decomposition is independent of the representation.
    \pause
    \item We may look at $G_u, G_s$, the sets of respectively semisimple, unipotent elements, which will provide insight into the structure of the group.
  \end{itemize}
  
\end{frame}

\begin{frame}
  \frametitle{Tori} 

  \begin{itemize}
  \item We call an linear algebraic group a \emph{torus} if it is isomorphic to a direct product of some $n$ copies of $\mathbb{G}_m$, the multiplicative group of units.
  \pause
  \item The intuition here is that this represents the diagonal, commuting elements of the group in some basis.
  \pause
  \item We call a torus maximal if it is maximal under inclusion.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Connected Solvable Groups} 

  \begin{itemize}
  \item A major result in the structure of linear algebraic groups is the structure of connected solvable groups.
  \pause
  \item In particular, we have the following, for $G$ a connected, solvable linear algebraic group.
  \begin{itemize}
  \pause
  \item $G_u$ is a closed, connected normal subgroup of $G$, and the commutator $[G,G] \leq G_u$
  \pause
  \item Maximal tori are conjugate, and for any maximal torus, $G$ is equal to the semidirect product of $G_u$ with $T$, with $N_G(T) = C_G(T)$
  \end{itemize}
  \pause
  \item The upshot here is that for connected solvable groups, we may think of them as a diagonal matrix with a upper triangular matrix, up to some twisting.
  \end{itemize}
  
\end{frame}

\section{Lie Algebras}

\begin{frame}
  \frametitle{Definition of Lie algebra} 
  \begin{itemize}
  \item An \emph{algebra} $A$ is a vector space over a field $k$ equipped with a bilinear form $\cdot: A \times A \to A$ that sends $(x,y) \mapsto x \cdot y$ such that scalars distribute over addition and scalar multiplication is compatible with the form.
    \pause
  \item If we have that $x \cdot x = 0$ for all $x$ and for any $x, y, z \in A$, that  $(x \cdot (y \cdot z)) +  (y \cdot (z \cdot x)) +  (z \cdot (x \cdot y)) = 0$, we call $A$ a \emph{Lie algebra}, and the bilinear form a \emph{Lie bracket}.
  \pause
  \item Example: n-by-n square matrices with the bracket $[A, B] = AB  - BA$, where the multiplication is standard matrix multiplication, is a Lie algebra.
  \end{itemize} 
\end{frame}

\begin{frame}
\frametitle{Similar Algebraic Terminology}
\begin{itemize}
\item First, we call a subspace $I \subseteq L$ an \emph{ideal}, if, for all $x \in L, y \in I$, $[x,y] \in I$. We call $[L, L]$ the ideal consisting of linear combinations of $[l, lâ€™]$.
\pause
\item We call $L$ solvable if, for $L^{(0)} = L$, and $L^{(i)} = [ L^{(i-1)}, L^{(i-1)}]$, $L^{(i)}$ is trivial for some $i$.
\pause
\item Similarly, we call $L$ nilpotent if, for $L^0 = G$, and $L^i = [ L^{i-1}, L]$, $L^i$ is trivial for some $i$.
\pause
\item Evidently, if $L$ is nilpotent, certainly $L$ is solvable. % show this
\pause
\item You may notice that this is exactly in parallel with the group concepts, with ideals playing the same role as subgroups in the linear algebraic group setting.
\pause
\item  Note that here, we will restrict ourselves primarily to semisimple Lie algebras, which for our purposes will mean containing no solvable ideals.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Jordan Decomposition pt. 1}
  \begin{itemize}
  \item The ability to embed a Lie algebra into linear transformations (eq. endomophisms of vector spaces) allows us to characterize elements via properties of the endomorphism, assuming they are well-defined with respect to the representation.
    \pause
  \item In particular, we can define a \emph{Jordan decomposition} for Lie algebras.
  \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Jordan Decomposition pt. 2}
\begin{itemize}
    \item For a Lie algebra $L$, define the adjoint representation $\operatorname{ad}: L \to \operatorname{Der}(L) \subseteq \operatorname{End}(L)$ that takes an element $x \in L$ to the map $y \mapsto [xy]$. 
    \pause
    \item $\operatorname{Der}(L)$ contains the Jordan decomposition for each of its elements in $\operatorname{End}(L)$ and, for a semisimple Lie algebra $L$, the adjoint representation is bijective. Hence, we have a natural Jordan decomposition for $L$, as $x = s + n$, for $s$ semisimple, $n$ nilpotent.
    \pause
    \item So long as we have a finite-dimensional representation $\phi: L \to \operatorname{End}(V)$, with $L$ semisimple, that the typical Jordan decomposition into semisimple and nilpotent matrices coincides with the abstract.
  \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Toral Subalgebras and Root Spaces}
\begin{itemize}
\item As in the group setting, we will move towards a decomposition of semisimple Lie algebras.
\pause
\item First, we will define \emph{toral subalgebras} and \emph{root spaces}.
\pause
\item Recalling the Jordan decomposition, we call a subalgebra of $L$, $T$ toral, if $T$ is composed of semisimple elements. Moreover, if $T$ is maximal under inclusion, we call $T$ maximal, and typically denote it as $H$. One may prove that toral subalgebras are abelian.
\pause
\item Now, using the fact that  $\operatorname{ad}$ acts on $L$, we can look at eigenspaces of $H$. We define the root space with respect to the eigenvalue functional $\alpha$ as $L_\alpha = \{ x \in L : [hx] = \alpha(h) x \}$, where, since $H$ is a subalgebra, each $h \in H$ may have a different eigenvalue. This is well-defined, as $H$ consisting of commuting, semisimple elements gives us simultaneous eigenspaces.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Root space example}
\begin{itemize}
\item Take $L = \mathfrak{sl}_2(\mathbb{C})$, the set of $2 \times 2$ matrices with vanishing trace. We can see the set of matrices that have form $h = \begin{pmatrix} a & 0 \\ 0 & -a \end{pmatrix}$ is a choice of maximally commuting semisimple elements.
\pause
\item We see that looking at the basis elements $x = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}$ and $y = \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix}$, that $[hx] = 2ax$, and $[hy] = -2ay$. Hence, we may identify $L_2$ as spanned by $x$ and $L_{-2}$ as spanned by $y$. 
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Decomposition of a Semisimple Lie Algebra}
\begin{itemize}
\item The fact that $H$ is a commuting set of semisimple elements acting on $L$ allows us to say more - we actually may obtain a decomposition into a direct sum of subalgebras for $L$ in terms of toral algebras and root spaces.
\pause
\item For $L$ a semisimple Lie algebra, we have a \emph{root space decomposition} given by $L = H \oplus \amalg_{\alpha} L_\alpha$
\pause
\item In the same vein as the last example, we saw that we could break down $\mathfrak{sl}_2(\mathbb{C})$ as $H \oplus L_2 \oplus L_{-2}$.
\end{itemize}
\end{frame}

% figure out what I want to say about connections

\section{The Lie algebra of a linear algebraic group}

\begin{frame}
\frametitle{Preamble}
\begin{itemize}
\item As we have seen, the story of Lie algebras and linear algebraic groups parallel each other very closely.
\pause
\item In fact, there is a natural way to associate a Lie algebra to a linear algebraic group.
\pause
\item This will give some justification to why we choose our parallel naming and structures to two objects that do not immediately seem to have a close connection.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Derivations}
\begin{itemize}
\item Recall our definition of an algebra earlier, $A$. Let $\delta:  A \to A$ be a $k$-linear map. We call it a \emph{derivation} if $\delta(xy) = x \delta(y) + \delta(x)y$ for all $x, y \in A$.
\pause
\item In fact, we may show that the set of derivations $\operatorname{Der}(A)$ satisfies the properties of a Lie algebra, with the bracket $[\delta, \lambda] = \delta \lambda - \lambda \delta$
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{The Lie Algebra of a linear Algebraic Group}
\begin{itemize}
\item Recall the coordinate ring of a group $G$, $k[G]$, which we can think of as polynomials in the coordinates of $G$.
\pause
\item For a fixed $g \in G$, define $\lambda_g$ as left translation of a $f \in k[G]$ that sends $f(h) \mapsto \lambda_g(f)(h) = f(g^{-1}h)$ for all $h \in G$.
\pause
\item Taking the left-invariant derivations $\mathcal{L}(G) = \{ \delta \in \operatorname{Der}(k[G]) : \delta \lambda_g = \lambda_g \delta $ for all $g \in G \}$, we may see this as a Lie subalgebra of the derivations. We declare this to be the Lie algebra of $G$. 
\pause
\item Note that we may show that this is isomorphic to the tangent space of $G$ evaluated at the identity.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Consequences of the Association}
\begin{itemize}
\item For a morphism $\varphi: G \to Gâ€™$, we can see that the differential $d\varphi_e: T_e(G) \mapsto T_e(Gâ€™)$ that sends a point-derivation $x \in T_e(G)$ at the point $e \in G$ to a point derivation acting on a coordinate function $f \in k[Gâ€™]$ via $d\varphi_e(x)(f) = x(f \circ  \varphi)(e)$ is a hom of Lie algebras.
\pause
\item Examining the differential of inner automorphisms, if $A, B$ are closed subgroups, $C$ the closure of the group generated by $[A,B]$, we may show $\mathfrak{c} = \operatorname{Lie}(C)$ to contain all elements of the form $[x,y]$ for all $x \in \mathfrak{a} = \operatorname{Lie}(A), y \in \mathfrak{b} = \operatorname{Lie}(B)$.
\pause
\item Setting $A, B = G$, and letting $H = [G, G]$, we see then that $[\mathfrak{g}, \mathfrak{g} ] \subseteq \mathfrak{h}$. Thus, we can see if $G$ is solvable, so too is $\mathfrak{g}$.

\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Example}
\begin{itemize}
\item Take $G = \operatorname{SL}(2,k)$. Viewing this as a subgroup of $\operatorname{GL}(2,k)$, we may see its Lie algebra as a Lie subalgebra of $M(2,k)$.
\pause
\item It may be proved that $\mathfrak{sl}(2,k)$ is the subalgebra that sends the vanishing ideal of $\operatorname{SL}(2,k)$ to $0$ evaluated at the identity.
\pause
\item Writing the vanishing ideal as $ad - bc -1 = 0$, and evaluating at the identity as $a = d = 1$, we see that the partials with respect to $b, c$ are free, and if the coefficients of the partials with respect to $a, d$ must be equal and opposite. 
\pause
\item Hence, we may identify the Lie algebra as coefficients in $\begin{pmatrix} a & b \\ c & -a \end{pmatrix}$, which we recognize as isomorphic to $\mathfrak{sl}(2,k)$. 
\end{itemize}
\end{frame}

\section{Semisimple Classification}

\begin{frame}
\frametitle{Root Systems}
\begin{itemize}
\item We define a \emph{root system} as a set of vectors $\Phi$ in a Euclidean space $E$ such that:

(i) $\Phi$ spans $E$

(ii) If $\alpha \in \Phi$, then $k \alpha \in \Phi$ if and only if $k = \pm 1$.

(iii) For each $\alpha \in \Phi$, $\Phi$ is closed under reflection by the hyperplane defined by $\alpha$.

(iv) For any $\alpha, \beta \in \Phi$, $\frac{2 (\beta, \alpha)}{(\alpha, \alpha)} \in \mathbb{Z}$, with $( \cdot, \cdot)$ the standard inner product.
\pause
\item Define $\Delta = \{ \alpha_1, ..., \alpha_n \}$ as a base if $\Delta$ is a basis for $E$ and for any $\beta \in \Phi$, $\beta$ may be expressed as $\beta = \sum_{\alpha \in \Delta} k_\alpha \alpha$ with either all $k_\alpha$ non-negative or non-positive.
\pause
\item Note that the last condition is very restrictive. In fact, this reduces the number of irreducible root systems to 4 families and 5 exceptional ones.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Classification of Semisimple Lie Algebras}
\begin{itemize}
\item The upshot of root systems is the following theorem: Let $\Phi$ be an irreducible root system. Then, with a specified set of generators relative to a fixed base $\Delta$,  we may find a finite dimensional, semisimple Lie algebra $L$ with $\Phi$ as its root system, and its CSA spanned by the $h$â€™s.
\pause
\item Moreover, if two semisimple Lie algebras $L, Lâ€™$ have isomorphic root systems, we may find an an isomorphism $L \to Lâ€™$ from the root system isomorphism.
\pause
\item Thus, we may classify at least semisimple Lie algebras up to isomorphism just by looking at the combinatorial data of root systems.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Classification of Semisimple linear algebraic groups}
\begin{itemize}
\item Similarly, we have the same concept in linear algebraic groups, however, the root system on its own is not enough to determine a group up to isomorphism.
\pause
\item If we define abstract coroots as $\alpha^\vee = \frac{2 \alpha}{(\alpha, \alpha)}$, then, we can look at the root datum consisting of characters, roots, cocharacters, and concrete coroots $(X, \Phi, Y , \Phi^\vee)$.
\pause
\item The result then is that for each root datum, there exists a semisimple linear algebraic group with said root datum, and two groups are isomorphic if and only if they have isomorphic root datum.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Example - $\operatorname{SL}(2,k)$}
\begin{itemize}
\item We look at $\operatorname{SL}(2,k)$ and $\operatorname{PGL}(2,k) \cong \operatorname{GL}(2,k)/\{ cI : c \in k \}$.
\pause
\item Without proof, we claim that the roots for $\operatorname{SL}(2,k)$ are $\pm \alpha$ that sends a toral element to $a^2, a^{-2}$ respectively, and we can identify this as $A_1$.
\pause
\item When we look at coroots, for $\operatorname{SL}(2,k)$ the coroot $\alpha^\vee$ is $t \mapsto \begin{pmatrix} t & 0 \\ 0 & t^{-1} \end{pmatrix}$, as the composition of $\alpha \circ \alpha^\vee$ sends $t \mapsto t^2$.
\pause
\item Hence, we see that the coroot generates the entirety of the cocharacters, as we may send $t$ to any power of a toral element.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Example - $\operatorname{PGL}(2,k)$}
\begin{itemize}
\item Similarly, roots for $\operatorname{PGL}(2,k)$ $\pm \beta$ send a toral element to $a, -a$ respectively, and so these both have the same form as $A_1$, being exactly one root and its negative.
\pause
\item On the other hand looking at coroots, we must have that $\beta^\vee$ sends $t \mapsto \begin{pmatrix} 1 & 0 \\ 0 & t^{2} \end{pmatrix}$.
\pause
\item In contrast here, we cannot cover every cocharacter. Consider the map that sends $t \mapsto \begin{pmatrix} 1 & 0 \\ 0 & t \end{pmatrix}$. This is a well-defined cocharacter, but cannot be expressed as some composition of $\beta^\vee, -\beta^\vee$. Ergo, $\operatorname{SL}(2,k)$ and $\operatorname{PGL}(2,k)$ cannot have isomorphic root datum, and must be distinct.
\end{itemize}
\end{frame}

\end{document}

